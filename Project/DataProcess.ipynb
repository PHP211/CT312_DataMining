{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvi\n",
    "import re\n",
    "import json\n",
    "from pyvi import ViTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessing():\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        \n",
    "    def segmentation(self):\n",
    "        return ViTokenizer.tokenize(self.text)\n",
    "    \n",
    "    def split_words(self):\n",
    "        text = self.segmentation()\n",
    "        try:\n",
    "            SPECIAL_CHARACTER = '.,!?;:\"\\'[]{}()<>@#$%^&*+-/\\\\|=~`_'\n",
    "            return [x.strip(SPECIAL_CHARACTER).lower() for x in text.split()]\n",
    "        except TypeError:\n",
    "            return []\n",
    "        \n",
    "    def covert_unicode(self):\n",
    "        return re.sub(\n",
    "            r'à|á|ả|ã|ạ|â|ấ|ầ|ẩ|ẫ|ậ|ă|ắ|ằ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ê|ế|ề|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ô|ố|ồ|ổ|ỗ|ộ|ơ|ớ|ờ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ư|ứ|ừ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Â|Ấ|Ầ|Ẩ|Ẫ|Ậ|Ă|Ắ|Ằ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ê|Ế|Ề|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ô|Ố|Ồ|Ổ|Ỗ|Ộ|Ơ|Ớ|Ờ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ư|Ứ|Ừ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
    "            lambda x: self.dicchar[x.group()],self.txt\n",
    "        )\n",
    "        \n",
    "    def replace_acronyms(self):\n",
    "        acronyms = []\n",
    "        list_text = self.text.split(\" \")\n",
    "        for i in range(len(list_text)):\n",
    "            for j in range(len(acronyms)):\n",
    "                if(list_text[i] == acronyms[j][0]):\n",
    "                    list_text[i] = acronyms[j][1]\n",
    "        self.text = \" \".join(list_text)\n",
    "        return self.text    \n",
    "    \n",
    "    def lowercase(self):\n",
    "        self.text = self.text.lower()\n",
    "        return self.text        \n",
    "    \n",
    "    def remove_loop_char(self):\n",
    "        self.text = re.sub(r'([A-Z])\\1+', lambda m: m.group(1).upper(), str(self.text), flags=re.IGNORECASE)\n",
    "        self.text = re.sub(\n",
    "            r'[^A-Za-zÀ-ỹ\\s]',\n",
    "            ' ', self.text\n",
    "        )\n",
    "        return self.text\n",
    "     \n",
    "    def remove_stopwords(self):\n",
    "        stopwords = []\n",
    "        split_words = self.split_words()\n",
    "        words = []\n",
    "\n",
    "        for word in split_words:\n",
    "            if word not in stopwords:\n",
    "                words.append(word)\n",
    "\n",
    "        return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã xử lý xong và lưu vào file output.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def process_json_file(input_file, output_file):\n",
    "    # Bước 1: Đọc dữ liệu từ file JSON\n",
    "    with open(input_file, 'r', encoding='utf-8') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Bước 2: Xử lý từng mục trong dữ liệu JSON, bỏ trường cuối cùng (\"time\")\n",
    "    processed_data = []\n",
    "    for entry in data:\n",
    "        # Xóa trường cuối cùng \"time\"\n",
    "        if \"time\" in entry:\n",
    "            del entry[\"time\"]\n",
    "        \n",
    "        # Kiểm tra nếu các trường title, subtitle có dữ liệu cần xử lý\n",
    "        if 'title' in entry:\n",
    "            processor = DataPreprocessing(entry['title'])\n",
    "            entry['title'] = processor.split_words()\n",
    "        \n",
    "        if 'subtitle' in entry:\n",
    "            processor = DataPreprocessing(entry['subtitle'])\n",
    "            entry['subtitle'] = processor.split_words()\n",
    "        \n",
    "        processed_data.append(entry)\n",
    "\n",
    "    # Bước 3: Lưu dữ liệu đã xử lý vào file JSON mới\n",
    "    with open(output_file, 'w', encoding='utf-8') as json_output_file:\n",
    "        json.dump(processed_data, json_output_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Đã xử lý xong và lưu vào file {output_file}\")\n",
    "\n",
    "# Ví dụ sử dụng:\n",
    "process_json_file('genk_internet.json', 'output.json')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
